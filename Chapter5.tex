\chapter{Design and Implementation of a Test-Bed for the Self-Organizing Control of a Cloud Based Autonomic System} % Write in your own chapter title
\label{Chapter5}
\lhead{Chapter \ref{Chapter5}. \emph{Design and Implementation of a Test-Bed for the Self-Organizing Control of a Cloud Based Autonomic System}} % Write in your own chapter title to set the page header

In order to test the performance of the self-organizing system previously described, a test bed was developed and deployed to simulate a small cloud of servers. For the self-optimization tests, the testing is done with one cloud only as the self-organizing self-optimizing system works at the level of a cloud and not at the level of multi clouds as in the case of the geographically distributed cloud. For the geographically distributed cloud, each of the clouds will have it's own optimization.

\subsection{Cloud Test Bed}

A small test bed was used where various loads were applied to a cloud of media servers and the required data was measured from the servers. All servers are currently located in the same location on the same LAN and VLANs are used in order to separate servers into different logical networks. This is done in order to be able to simulate multiple datacenters (clouds) and be able to simulate network load on the connections between datacenters to test the geographically distributed cloud. Each of the hardware servers in the cluster run Docker \cite{cloud:docker}. Each docker container runs the Ubuntu OS and the required software for the container. A number of containers are used by the application:

\begin{enumerate}
	\item Media server container
	\item JGroups container for the communication between servers
	\item Load balancer container for the cloud
	\item Gateway container for cloud to cloud communication
	\item Self-optimizing manager container for the cloud
	\item Self-organizing manager for a single media cloud container
\end{enumerate}

Figure \ref{fig:deployment} shows the physical topology of the infrastructure, which will be used to simulate various deployment scenarios and run tests on how the collaborative system behaves. The test bed uses five servers connected via a switch to one of four routers with a fifth router providing outside internet connection. Figure \ref{fig:logicaldeploymentrouting} displays how routing will be done within the network and the various VLANs used to create the separate clouds. The server names are cloud1 through cloud5, with cloud4 and cloud5 being in the same VLAN, while cloud1, cloud2 and cloud3 are each in their own VLAN. The network connections are 100Mbps with some of the router connections being 10Mbps. While such connection speeds would be too low for a datacenter, it is fine for these tests as the low speeds can be used to simulate overloaded internet connections with low throughput.

\begin{figure}
	\centering
		\includegraphics[width=\columnwidth]{01_physical_topology_v2_abstr}
	\caption{Physical Topology}
	\label{fig:deployment}
\end{figure}

\begin{figure}
	\centering
		\includegraphics[width=\columnwidth]{05_logical_topology_routing_protocols_v2_abstr}
	\caption{Logical Topology Routing}
	\label{fig:logicaldeploymentrouting}
\end{figure}

A separate machine not shown in the diagrams is responsible for simulating client requests. In order to test audio/video streaming a prerecorded webcam video is streamed whenever the client simulator decides to start streaming. The stream used for testing is a 64x64 video stream at 25 frames per second with a bit rate of 180Kbps. The client simulator is written in Java and can simulate various client distributions by varying the amount of clients, the number of clients in every session, the number of clients streaming in each session and the time delay between messages being sent in a session. The simulator initially creates a number of sessions and a number of clients in each session. Each client is created with a given time to live. Periodically, the session calculates how many clients should be streaming in the session at that point in time. If more clients are required to stream than are currently streaming, the session simulator instructs a number of clients to start streaming also. If less clients are required to stream than are currently streaming, the session simulator instructs a number of clients to stop streaming. If there is no change in the number of clients needed to stream, then no change is made in which clients are streaming. Whenever a client reaches its time to live, the client is put to sleep and given a time after which it should wake up and reactivate. When a client reactivates it joins again the same session it was a member of, before going to sleep. The amount of time clients are awake and sleep is randomized thus generating various session sizes over time.

\section{Autonomic Computing Self-Organizing Tests}

The testbed described in the previous section will be used in order to evaluate the performance of the self-optimizing self-organizing autonomic system presented in this thesis.

\subsection{System Measurements}

First of all, using the test bed a number of runs were performed in order to determine the behaviour of geographically distributed media cloud. The tests vary one of four variables in order to determine how they affect the outputs of the media server clouds. For each of the tests presented in the following subsections one variable was modified while all others were kept constant. The four variables are the following:

\begin{enumerate}
	\item Number of servers in the cloud, varied from one to three.
	\item Number of collaborative sessions in each server, varied from one to six.
	\item Number of clients in each session, varied in increments of one from two to forty. In some cases, the increases in clients stopped before reaching the maximum due to the 10Mbps network link becoming saturated.
	\item Number of clients streaming per session, varied from one to four. 
\end{enumerate}

The tests presented here represent an exhaustive search of the variable space in order to determine how each of the four variables affects the system under test.

\subsection{Test Plan}

The data is measured from all the servers every 30 seconds, and is composed of: bandwidth received, bandwidth sent, latency and CPU usage. Since the tests are run at different moments in time, the timescale is normalized to the period from when each test was started.

The expectations are that as the number of servers increases for a given number of clients, sessions and streams the bandwidth and latency will decrease proportionally. Similar, as the number of collaborative sessions increases, with all other variables kept constant bandwidth and latency will decrease as the 1:N proportion, where N is how many clients receive the stream decreases. When the number of clients in a session increases bandwidth and latency should increase in a reverse fashion. Finally, when the number of streaming clients increases bandwidth and latency should increase similarly.

The graphs for the performance tests can be found in Appendix \ref{appendix:modelidentifperfresults}. In order to make the results more visible, the tests are grouped on the graphs 3 by 3, with the lowest test on one graph being the highest test on another graph. The following sections will present the results in tabular form.

In order to simplify notations, test will be abbreviated in the form clouds/servers/sessions/incoming streams per session. For a single cloud, the clouds part will be missing. For example, the test 2/3/1/4 refers to a test with 2 clouds, 3 servers, 1 session across all servers and 4 incoming streams from clients. Also, some of the test results will be skipped to preserve space.

\subsubsection{1 Server, 1 Collaborative Session, 1 Stream Per Session}
\label{sec:1serv_1sess_1str}

The number of clients was varied from 2 to 40 in increments of 1. The number of outgoing streams is equal to (the number of users - 1) because the streaming user does not receive the stream back. These results show that as the number of users increases in a session, the latencies and CPU usage of the server increase at the same time. Interestingly CPU usage seems to reach an upper bound around 34 users while latencies continue to increase.

\subsubsection{1 Server, 1 Collaborative Session, 2 Streams Per Session}
\label{sec:1serv_1sess_2str180}

The number of clients was varied from 2 to 20 in increments of 1. The number of outgoing streams in this case will be equal to 2 * (the number of users - 1), as there are 2 streams going to all users in the session except the streamer. The pattern is similar to the previous case, with latencies and CPU usage increasing as the number of users in the session increases. Similar to before, CPU reaches a point where it peaks while latencies still increase. If similar numbers of outgoing streams were to be compared, it can be seen that the results are similar in both CPU usage and latency at lower number of users. For example, for 12 outgoing streams the previous test had a median CPU of 19.28 \% and median latency of 15.69 ms, while this test has a median CPU of 19.35 \% and median latency of 16.71ms. As the number of users increases however, the results of this test case are worse than the equivalent result of the previous test. For example, for 26 outgoing streams the previous test had a median CPU of 36.09 \% and median latency of 20.63 ms, while this test has a median CPU of 31.06 \% and median latency of 22.64 ms.

\subsubsection{1 Server, 1 Collaborative Session, 3 Streams Per Session}
\label{sec:1serv_1sess_3str180}

The number of clients was varied from 3 to 14 in increments of 1. The number of outgoing streams in this case will be equal to 3 * (the number of users - 1), as there are 3 streams going to all users in the session except the streamer. Like in the two previous cases CPU and latency increase as more users are added to the session. At similar levels of outgoing streams, the results for this test case are a bit worse than those of the two previous tests. For 12 outgoing streams, this results in a median latency of 20.41 ms, which is higher than 16.71 ms for the previous test and 15.69 ms for the first test.

\begin{table}
\caption{Median and Mean CPU, Latencies for 1 Server, 1 Session, 3 Stream}
\label{table:1serv_1sess_3str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
3 & 11.83 & 26.84 & 10 & 159.44 & 12.2 & 10.36 & 6 \\
4 & 11.75 & 23.48 & 10 & 22.25 & 16.49 & 14.38 & 9 \\
5 & 13.2 & 28.18 & 9 & 139.88 & 20.41 & 16.79 & 12 \\
6 & 17 & 22.06 & 10 & 53.82 & 20.04 & 16.42 & 15 \\
7 & 17.43 & 24.73 & 10 & 17.33 & 22.94 & 19.22 & 18 \\
8 & 16.25 & 28.08 & 10 & 32.48 & 26.24 & 22.29 & 21 \\
9 & 20.11 & 43.52 & 10 & 25.36 & 31.03 & 26.28 & 24 \\
10 & 19.3 & 31.01 & 11 & 53.42 & 34.48 & 29.43 & 27 \\
11 & 25.73 & 75.89 & 15 & 46.64 & 32.74 & 27.37 & 30 \\
12 & 30 & 67.83 & 15 & 45.34 & 35.04 & 29.77 & 33 \\
13 & 45.08 & 99.52 & 32 & 53.17 & 36.2 & 30.95 & 36 \\
14 & 76.82 & 112.76 & 34 & 39.84 & 39.52 & 34.06 & 39 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{1 Server, 1 Collaborative Session, 4 Streams Per Session}
\label{sec:1serv_1sess_4str180}

For this test, users were varied from 4 to 11 in increments of 1. Outgoing streams behave as previous and will be equal to 4 * (the number of outgoing streams). Same results as for the previous tests are observed, as median latency for 12 outgoing streams is even higher than the previous tests.

\begin{table}
\caption{Median and Mean CPU, Latencies for 1 Server, 1 Session, 4 Stream}
\label{table:1serv_1sess_4str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
4 & 11.88 & 17.23 & 10 & 14.55 & 21.59 & 18.1 & 12 \\
5 & 14.2 & 20.44 & 10 & 38.31 & 21.88 & 18.22 & 16 \\
6 & 18.33 & 26.47 & 11 & 37.45 & 27.19 & 22.72 & 20 \\
7 & 20.14 & 39.64 & 11.5 & 32.15 & 33.14 & 27.96 & 24 \\
8 & 22.62 & 49.37 & 13 & 26.71 & 35.71 & 30.28 & 28 \\
9 & 32.89 & 79.52 & 20.5 & 34.98 & 35.84 & 29.86 & 32 \\
10 & 30 & 82.61 & 24.5 & 54.45 & 37.32 & 31.55 & 36 \\
11 & 69.45 & 107.49 & 40 & 45.13 & 38.35 & 32.62 & 40 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{1 Server, 2 Collaborative Sessions, 1 Stream}
\label{sec:1serv_2sess_1str180}

In this test 2 collaborative sessions of equal size are created, but only one session contains a streaming client. In the second session, clients only exchange text/synchronization messages. The goal of this test is to determine if there are other factors in the application outside video/audio streaming impacting latencies and CPU usage. If this test was compared to the test in section \ref{sec:1serv_1sess_1str}, it would be expected that latencies are very similar for equal numbers of clients. This expectation is not met however, as similar numbers of users result in higher latencies for this test. CPU usage values are very close for all tests however. This suggests that first of all, latencies are not directly related to CPU usage, and at the same time that only the number of outgoing streams is not sufficient to determine the latency of the system.

\subsubsection{1 Server, 2 Collaborative Sessions, 2 Streams (one stream per session)}
\label{sec:1serv_2sess_2str}

Unlike the previous test, in this test both sessions contain a user which is streaming audio/video data. The assumption is that the results for this test will be very similar to the results from section \ref{sec:1serv_1sess_2str180}, since both tests will exhibit the same number of incoming streams, outgoing streams and stream multiplicity but with different number of users connected and different number of sessions. Similar to the previous test with 2 sessions, while the CPU usage is similar for equivalent outgoing streams to the 1 session test with similar streams, median latencies are higher for this test.

\subsubsection{1 Server, 2 Collaborative Sessions, 3 Streams}
\label{sec:1serv_2sess_3str}

In order to have a test with 3 streams for 2 sessions, one session will have 2 users streaming and the other session will only contain a single user who is streaming. The highest result shown is for 14 users per session, due to the fact that at 14 users per session, the 10 Mbps link is saturated.

Comparing this test result, with the results from Table \ref{table:1serv_1sess_3str}, the same pattern as before is observed - the test with a higher number of sessions (and more total users connected to the server) exhibits higher latencies for the same number of incoming and outgoing streams. This difference becomes larger with a higher number of users. At the same time, CPU usage values are virtually the same between the two tests while latencies are higher for this test when compared to the 1/1/3 test.

\subsubsection{1 Server, 2 Collaborative Sessions, 4 Streams}
\label{sec:1serv_2sess_4str}

The same trend as before is shown by this test when compared to both the previous tests with 2 sessions and to the 1/1/4 test.

\begin{table}
\caption{Median and Mean CPU, Latencies for 1 Server, 2 Session, 4 Stream}
\label{table:1serv_2sess_4str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
2 & 12.25 & 16.02 & 12 & 58.94 & 10.91 & 9.42 & 4 \\
3 & 16 & 24.18 & 12 & 20.44 & 16.75 & 13.7 & 8 \\
4 & 16.69 & 23.48 & 12 & 17.18 & 21.78 & 18.28 & 12 \\
5 & 16.25 & 27.37 & 11 & 52.32 & 22.55 & 19.18 & 16 \\
6 & 19.17 & 31.97 & 12 & 30.2 & 28.5 & 23.87 & 20 \\
7 & 22.79 & 49.1 & 12.5 & 33.83 & 31.85 & 26.27 & 24 \\
8 & 27.38 & 77.3 & 12.5 & 26.23 & 37.85 & 32.18 & 28 \\
9 & 45 & 77.44 & 20 & 35.24 & 36.82 & 31.38 & 32 \\
10 & 71.6 & 116.25 & 21 & 35.18 & 38.2 & 32.99 & 36 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{1 Server, 3 Collaborative Sessions, 3 Streams}
\label{sec:1serv_3sess_3str}

Comparing this test results with the results from Table \ref{table:1serv_1sess_3str} and Table \ref{table:1serv_2sess_3str}, for the same number of outgoing streams, CPU usage is very similar, while latencies are higher for this test. The reason for this, is that a similar number of outgoing streams for this case has more total users across the server.

\begin{table}
\caption{Median and Mean CPU, Latencies for 1 Server, 3 Session, 3 Stream}
\label{table:1serv_3sess_3str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
2 & 14 & 19.06 & 11 & 16.43 & 8.3 & 7.43 & 3 \\
3 & 13.56 & 17.83 & 11 & 40.74 & 12.6 & 10.84 & 6 \\
4 & 16.17 & 18.44 & 11 & 28.72 & 16.86 & 14.9 & 9 \\
5 & 16.33 & 28.52 & 10 & 15.91 & 20.82 & 18.06 & 12 \\
6 & 19.89 & 28.45 & 11 & 18.02 & 20.84 & 17.52 & 15 \\
7 & 22.81 & 34.21 & 11 & 18.98 & 23.46 & 19.77 & 18 \\
8 & 20.9 & 38.72 & 11 & 21.45 & 29.21 & 24.71 & 21 \\
9 & 27.81 & 40.85 & 11 & 22.38 & 33.17 & 27.21 & 24 \\
10 & 35.65 & 73.61 & 11 & 26.09 & 35.04 & 29.64 & 27 \\
11 & 44.55 & 82.58 & 14.5 & 33.29 & 35.46 & 30.34 & 30 \\
12 & 40.06 & 111.62 & 15 & 31.79 & 38.11 & 31.4 & 33 \\
13 & 107.77 & 134.55 & 27.5 & 40.45 & 39 & 32.78 & 36 \\
14 & 71.73 & 126.28 & 18 & 31.79 & 39.02 & 28.9 & 39 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{1 Server, 3 Collaborative Sessions, 6 Streams}
\label{sec:1serv_3sess_6str}

Comparing this test results with the results from Table \ref{table:1serv_3sess_3str}, for the same number of outgoing streams, CPU usages are the same across all tests while latencies are lower for this test.

\begin{table}
\caption{Median and Mean CPU, Latencies for 1 Server, 3 Session, 6 Stream}
\label{table:1serv_3sess_6str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
2 & 15.83 & 32.21 & 12 & 74.8 & 16.38 & 14.41 & 6 \\
3 & 15 & 48.27 & 12 & 70.58 & 20.49 & 17.78 & 12 \\
4 & 17.17 & 37.78 & 12 & 74.22 & 28.6 & 24.74 & 18 \\
5 & 26.73 & 54.69 & 12 & 33.74 & 33.7 & 28.98 & 24 \\
6 & 39.17 & 89.78 & 16 & 37.98 & 35.88 & 31.55 & 30 \\
7 & 68.74 & 113.51 & 34 & 41.72 & 37.96 & 33.94 & 36 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{1 Server, 4 Collaborative Sessions, 4 Streams}
\label{sec:1serv_4sess_4str}

Comparing this test results with the tests in \ref{table:1serv_1sess_4str} and \ref{table:1serv_2sess_4str} across a similar number of outgoing streams, for 24 streams for example the latency medians are:

\begin{itemize}
	\item 20.14 for 1 session
	\item 22.79 for 2 sessions
	\item 33.57 for 4 sessions
\end{itemize}

This results suggests that the number of sessions plays an important factor in latency values.

\subsubsection{1 Server, 4 Collaborative Sessions, 8 Streams}
\label{sec:1serv_4sess_8sstr}

Comparing this test with \ref{sec:1serv_4sess_4str}, it can be seen that for similar numbers of outgoing streams, this test has similar or better results for latency but worse results for CPU usage.

\subsubsection{2 Servers, 1 Collaborative Session, 1 Stream Per Session}

In order to test the behaviour when multiple servers are present, sessions were created with a number of clients which is a multiple of the number of servers, such that the servers have the same number of clients due to the fact that clients are distributed to the servers in a Round Robin fashion. Only one of the two servers is shown in these tests, as the results are similar.

Comparing these results with those of \ref{table:1serv_1sess_1str}, it can be seen that the results are very similar for similar numbers of users and outgoing streams for both latencies and CPU usage. Due to the proxy stream between servers, an equal number of clients per server will have more outgoing streams.

\subsubsection{2 Servers, 1 Collaborative Session, 2 Streams}

Comparing this test with the test in \ref{table:1serv_1sess_2str} and the test in \ref{table:1serv_2sess_2str}, for a similar number of outgoing streams, the 1/1/2 test shows very similar results, while the 1/2/2 test shows worse results.

\subsubsection{2 Servers, 1 Collaborative Session, 3 Streams}

Comparing this test with the test in \ref{table:1serv_1sess_3str}, the latency and CPU usage are similar for an equal number of outgoing streams. Doing the same comparison with the test in \ref{table:1serv_2sess_3str}, the results are better for this result.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Server, 1 Session, 3 Stream}
\label{table:2serv_1sess_3str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
2 & 11 & 30.57 & 33 & 25.02 & 10.34 & 8.61 & 6 \\
3 & 14.33 & 22.17 & 32 & 24.33 & 13.46 & 11.44 & 9 \\
4 & 14.38 & 29.36 & 33.5 & 198.07 & 16.97 & 14.19 & 12 \\
5 & 15.2 & 20.99 & 35 & 86.81 & 19.98 & 16.18 & 15 \\
6 & 15.67 & 18.74 & 35 & 48.21 & 23.45 & 19.46 & 18 \\
7 & 19.14 & 36.61 & 36 & 33.92 & 26.53 & 22.04 & 21 \\
8 & 16.38 & 30.7 & 36 & 34.27 & 30.44 & 25.37 & 24 \\
9 & 19.22 & 38.75 & 37 & 39.36 & 33.24 & 26.62 & 27 \\
10 & 25.2 & 46 & 40.5 & 43.95 & 35.07 & 28.68 & 30 \\
11 & 21.45 & 59.71 & 45.5 & 104.72 & 36.31 & 29.23 & 33 \\
12 & 36 & 68.65 & 44 & 52.64 & 38.89 & 31.28 & 36 \\
13 & 62.77 & 91.37 & 60.5 & 69.6 & 40.33 & 33.35 & 39 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Servers, 1 Collaborative Session, 4 Streams}

Comparing this result, with the result of the test \ref{sec:1serv_1sess_4str}, while the outgoing number of streams can not be matched, the results look similar for similar numbers of outgoing streams.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Server, 1 Session, 4 Stream}
\label{table:2serv_1sess_4str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
2 & 12.5 & 20.29 & 36.5 & 35.82 & 13.47 & 11.29 & 6 \\
3 & 20.5 & 27.53 & 38 & 216.37 & 18.58 & 15.22 & 10 \\
4 & 12.5 & 18.94 & 37 & 160.24 & 21.92 & 18.36 & 14 \\
5 & 15.8 & 28.42 & 37 & 85.29 & 25.37 & 21 & 18 \\
6 & 21 & 40.7 & 40 & 140.82 & 31.58 & 26.35 & 22 \\
7 & 26.14 & 45.95 & 38.5 & 46 & 34 & 28.81 & 26 \\
8 & 52.88 & 71.33 & 41.5 & 147.94 & 34.94 & 29.29 & 30 \\
9 & 28.17 & 75.25 & 42 & 48.97 & 37.59 & 30.23 & 34 \\
10 & 60.4 & 103.87 & 51.5 & 79.08 & 38.15 & 31.1 & 38 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Servers, 2 Collaborative Session, 1 Streams}

Comparing this result, with the result of the test \ref{sec:1serv_2sess_1str}, for equal numbers of outgoing streams the results are similar for both tests.

\subsubsection{2 Servers, 2 Collaborative Sessions, 2 Streams}

Comparing the results in this test with those shown in Table \ref{table:1serv_2sess_2str}, this test shows similar results.

\subsubsection{2 Servers, 2 Collaborative Sessions, 3 Streams}

Comparing the results in this test with those shown in Table \ref{table:1serv_2sess_3str}, this test shows similar results.

\subsubsection{2 Servers, 2 Collaborative Sessions, 4 Streams}

Comparing this test result with the results in Table \ref{table:1serv_2sess_4str}, median latencies and CPU usage are similar for the two tests.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Server, 2 Session, 4 Stream}
\label{table:2serv_2sess_4str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
1 & 12 & 21.6 & 38 & 212.8 & 8.87 & 7.66 & 6 \\
2 & 14.75 & 20.69 & 38 & 60.44 & 15.15 & 12.87 & 10 \\
3 & 14.92 & 22.95 & 36 & 35.18 & 17.99 & 15.31 & 14 \\
4 & 17 & 28.44 & 38 & 52.17 & 23.22 & 19.85 & 18 \\
5 & 20.55 & 53.92 & 40 & 153.86 & 27.5 & 23.53 & 22 \\
6 & 18.71 & 29.53 & 31 & 37.44 & 32.09 & 26.85 & 26 \\
7 & 22.96 & 44.78 & 31.5 & 42.36 & 34.72 & 29.66 & 30 \\
8 & 29.5 & 72.35 & 32 & 45.71 & 35.07 & 29.36 & 34 \\
9 & 54.61 & 80.43 & 53 & 55.77 & 36.93 & 30.22 & 38 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Servers, 3 Collaborative Sessions, 3 Streams}

Comparing this result with the result shown in \ref{table:1serv_3sess_3str} this test shows better results for equal number of outgoing streams.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Server, 3 Session, 3 Stream}
\label{table:2serv_3sess_3str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
1 & 11.67 & 14.43 & 34 & 43.47 & 6.05 & 5.03 & 3 \\
2 & 15 & 20.36 & 32 & 44.73 & 9.86 & 8.15 & 6 \\
3 & 14.33 & 21.17 & 34 & 39.86 & 12.84 & 10.21 & 9 \\
4 & 15.5 & 23.41 & 31 & 60.03 & 17.13 & 14.5 & 12 \\
5 & 15.13 & 23.75 & 31 & 77.83 & 20.45 & 16.94 & 15 \\
6 & 17.94 & 27.41 & 31 & 36.41 & 24.4 & 20.32 & 18 \\
7 & 24.74 & 42.37 & 31 & 39.77 & 27.27 & 23.55 & 21 \\
8 & 22.56 & 36.68 & 32 & 45.23 & 31.56 & 26.32 & 24 \\
9 & 31.63 & 55.73 & 37 & 45.19 & 33.2 & 27.08 & 27 \\
10 & 35.4 & 63.26 & 34 & 65.25 & 34.82 & 28.93 & 30 \\
11 & 45.96 & 89.5 & 42.5 & 48.71 & 36.84 & 30.78 & 33 \\
12 & 59.78 & 108.02 & 46 & 54.76 & 36.97 & 30.82 & 36 \\
13 & 88.01 & 126.94 & 50.5 & 61.08 & 38.95 & 32.87 & 39 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Servers, 3 Collaborative Sessions, 6 Streams}

Comparing results between this test and the test shown in Table \ref{table:1serv_3sess_6str}, median latency is better for this test while CPU results are similar for equal number of outgoing streams.
 
\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Server, 3 Session, 6 Stream}
\label{table:2serv_3sess_6str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
1 & 13.67 & 27.24 & 38 & 112.94 & 13.02 & 11.24 & 6 \\
2 & 16.67 & 39.36 & 35 & 43.1 & 20.53 & 17.69 & 12 \\
3 & 15.56 & 23.39 & 38 & 59.07 & 27.73 & 24.17 & 18 \\
4 & 20.17 & 25.18 & 37 & 71.53 & 32.97 & 28.19 & 24 \\
5 & 20.93 & 52.74 & 32 & 45.75 & 35.89 & 31.04 & 30 \\
6 & 44.11 & 73.98 & 46.5 & 49.17 & 37.99 & 33.04 & 36 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Clouds, 2 Servers, 1 Collaborative Session, 1 Stream}

The system was also tested with multiple servers in multiple clouds. For this test, each of the two servers was in a different cloud with the collaborative session across all servers in the cloud. The CPU usage and median latencies are similar to those of the other tests with 1 session and 1 stream for equal numbers of outgoing streams. However, message latencies are much higher due to the data going between the two clouds.

\subsubsection{2 Clouds, 2 Servers, 1 Collaborative Session, 2 Streams}

The results for this test are again similar to the other results with 1 session and 2 streams, other than message latencies being higher.

\subsubsection{2 Clouds, 2 Servers, 1 Collaborative Session, 3 Streams}

The results for this test are better than the other results with 1 session and 3 streams, with message latencies being higher again.

\subsubsection{2 Clouds, 2 Servers, 1 Collaborative Session, 4 Streams}

The results for this test are better than the other results with 1 session and 4 streams, with message latencies being higher again.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Cloud, 2 Server, 1 Session, 4 Stream}
\label{table:2cld_2serv_1sess_4str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
2 & 10 & 12.81 & 66 & 67.9 & 4.1 & 3.29 & 6 \\
3 & 10 & 17.19 & 57.5 & 78.8 & 13.12 & 10.92 & 10 \\
4 & 11.33 & 20.39 & 47 & 93.38 & 16.81 & 13.89 & 14 \\
5 & 10.88 & 19.88 & 47 & 149.59 & 22.03 & 18.76 & 18 \\
6 & 13 & 26 & 45.5 & 41.61 & 27.4 & 22.92 & 22 \\
7 & 18 & 28.7 & 57 & 73.98 & 22.67 & 18.76 & 26 \\
8 & 19.71 & 32.06 & 60.5 & 87.04 & 26.76 & 24.69 & 30 \\
9 & 23.12 & 44.06 & 62 & 74.58 & 35.92 & 29.15 & 34 \\
10 & 27.33 & 60.67 & 62 & 64.28 & 39.92 & 32.22 & 38 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Clouds, 2 Servers, 2 Collaborative Sessions, 1 Stream}

The results for this test are again similar to the other results with 2 session and 1 stream, other than message latencies being higher. The results are worse than those of 2/2/1/1.

\subsubsection{2 Clouds, 2 Servers, 2 Collaborative Sessions, 2 Streams}

The results for this test are again similar to the other results with 2 session and 2 streams, other than message latencies being higher. The results are worse than those of 2/2/1/2.

\subsubsection{2 Clouds, 2 Servers, 2 Collaborative Sessions, 3 Streams}

The results for this test are again similar to the other results with 2 session and 3 streams, other than message latencies being higher. The results are worse than those of 2/2/1/3.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Cloud, 2 Server, 2 Session, 3 Stream}
\label{table:2cld_2serv_2sess_3str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
1 & 11 & 16.99 & 68 & 185.72 & 6.47 & 5.39 & 3 \\
2 & 12.25 & 17.7 & 46.5 & 42.61 & 10.19 & 8.43 & 6 \\
3 & 13.25 & 27.85 & 50 & 82.63 & 13.6 & 11.47 & 9 \\
4 & 15.25 & 34.36 & 54 & 53.52 & 17.27 & 13.95 & 12 \\
5 & 14.55 & 29.64 & 51 & 128.35 & 20.36 & 16.29 & 15 \\
6 & 17.08 & 21.92 & 62 & 110.4 & 23.08 & 19.49 & 18 \\
7 & 21.19 & 30.3 & 56 & 57.89 & 27.49 & 23.21 & 21 \\
8 & 23.12 & 32.26 & 58 & 60.11 & 31.08 & 24.37 & 24 \\
9 & 29.67 & 37.19 & 62 & 73.81 & 35.25 & 28.44 & 27 \\
10 & 36.93 & 59.72 & 63 & 68.62 & 35.87 & 28.92 & 30 \\
11 & 51.88 & 63.2 & 63.5 & 83.65 & 37.29 & 30.77 & 33 \\
12 & 81.43 & 103.52 & 78 & 84.21 & 36.92 & 31.05 & 36 \\
13 & 77.5 & 116.33 & 70 & 86.08 & 38.75 & 32.58 & 39 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Clouds, 2 Servers, 2 Collaborative Sessions, 4 Streams}

The results for this test are again similar to the other results with 2 sessions and 4 streams, other than message latencies being higher. The results are worse than those of 2/2/1/4.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Cloud, 2 Server, 2 Session, 4 Stream}
\label{table:2cld_2serv_2sess_4str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
1 & 12.5 & 20.75 & 34 & 78.53 & 66 & 67.9 & 6 \\
2 & 13.5 & 19.43 & 65 & 62.76 & 57.5 & 78.8 & 10 \\
3 & 15.75 & 34.59 & 64 & 54.37 & 47 & 93.38 & 14 \\
4 & 18.75 & 33.91 & 64 & 63.35 & 47 & 149.59 & 18 \\
5 & 15.25 & 21.07 & 64 & 45.68 & 45.5 & 41.61 & 22 \\
6 & 20.86 & 44.82 & 66.5 & 64.67 & 57 & 73.98 & 26 \\
7 & 24.69 & 46.96 & 67.5 & 70.52 & 60.5 & 87.04 & 30 \\
8 & 62 & 86.45 & 69 & 74.45 & 62 & 74.58 & 34 \\
9 & 100.85 & 135.53 & 75.5 & 90.05 & 62 & 64.28 & 38 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Clouds, 2 Servers, 3 Collaborative Sessions, 3 Stream}

The results for this test are better than those of 2/3/3, other than message latencies being higher.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Cloud, 2 Server, 3 Session, 3 Stream}
\label{table:2cld_2serv_3sess_3str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
1 & 10.33 & 13.79 & 63 & 70.75 & 6.24 & 5.08 & 3 \\
2 & 14 & 25.46 & 46.5 & 48.42 & 9.71 & 7.95 & 6 \\
3 & 13.67 & 17.43 & 46 & 44.35 & 13.27 & 10.74 & 9 \\
4 & 14.46 & 32.39 & 51.5 & 50.22 & 18.14 & 15.12 & 12 \\
5 & 14.2 & 21 & 50 & 49.24 & 20.54 & 16.63 & 15 \\
6 & 18.42 & 23.56 & 59.5 & 53.26 & 22.14 & 19.37 & 18 \\
7 & 21.45 & 40.37 & 66 & 58 & 24.53 & 20.37 & 21 \\
8 & 16.17 & 31.21 & 65 & 52.25 & 13.87 & 13.07 & 24 \\
9 & 47.59 & 67.91 & 66 & 55.65 & 35.57 & 29.96 & 27 \\
10 & 18 & 54.72 & 67.5 & 68.12 & 18.06 & 22.43 & 30 \\
11 & 38.97 & 45.49 & 59 & 60.21 & 1.64 & 10.75 & 33 \\
12 & 46.72 & 89.4 & 75 & 76.97 & 39 & 29.33 & 36 \\
\end{tabu}
\end{table}


\clearpage\subsubsection{2 Clouds, 2 Servers, 3 Collaborative Sessions, 6 Stream}

The results for this test are similar to the other results with 3 sessions and 6 streams, other than message latencies being higher. The results are similar to those of of 2/2/3/3, suggesting that the results of 2/2/3/3 are an outlier.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Cloud, 2 Server, 3 Session, 6 Stream}
\label{table:2cld_2serv_3sess_6str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
2 & 12.33 & 19.03 & 71 & 93.01 & 13.46 & 11.47 & 6 \\
3 & 14.33 & 21.91 & 58 & 70.67 & 19.67 & 16.62 & 12 \\
4 & 17.44 & 34.69 & 62 & 112.38 & 27.59 & 23.82 & 18 \\
5 & 18.67 & 25.39 & 58 & 58.12 & 32.91 & 28.9 & 24 \\
6 & 21.87 & 39.76 & 63 & 82.01 & 36.25 & 31.02 & 30 \\
7 & 47.33 & 79.9 & 65 & 101.52 & 40.03 & 34.98 & 36 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Clouds, 2 Servers, 4 Collaborative Sessions, 4 Streams}

The results for this test are better than test 1/4/4 for similar numbers of outgoing streams.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Cloud, 2 Server, 4 Session, 4 Stream}
\label{table:2cld_2serv_4sess_4str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
1 & 11 & 13.73 & 69 & 115.4 & 8.76 & 7.13 & 4 \\
2 & 11.75 & 18.5 & 50 & 43.13 & 13.89 & 11.56 & 8 \\
3 & 13.83 & 41.03 & 47 & 78.85 & 19.04 & 15.97 & 12 \\
4 & 18.31 & 27.02 & 52 & 49.39 & 22.46 & 18.76 & 16 \\
5 & 16.9 & 24.93 & 62 & 231.75 & 25.39 & 22.01 & 20 \\
6 & 15.62 & 33.56 & 47.5 & 102.4 & 26.98 & 23.35 & 24 \\
7 & 23.54 & 34.5 & 62 & 63.52 & 36.86 & 31.11 & 28 \\
8 & 41.09 & 93.96 & 62 & 84.31 & 36.66 & 31.11 & 32 \\
9 & 55.11 & 85.8 & 63 & 67.16 & 37.1 & 30.6 & 36 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Clouds, 2 Servers, 4 Collaborative Sessions, 8 Streams}

The results for this test are better than test 1/4/8 for similar numbers of outgoing streams.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Cloud, 2 Server, 4 Session, 8 Stream}
\label{table:2cld_2serv_4sess_8str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users/Session/Server & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
1 & 16.62 & 25.97 & 47 & 61.4 & 25.64 & 21.6 & 8 \\
2 & 20 & 24.06 & 54 & 52.67 & 33.75 & 28.47 & 16 \\
3 & 35.06 & 52.66 & 56 & 57.65 & 36.14 & 29.98 & 24 \\
\end{tabu}
\end{table}

\clearpage\subsubsection{2 Clouds, 3 Servers, 1 Collaborative Session, 1 Stream}

For the 2 clouds with 3 servers tests, two of the servers were placed in the same cloud with another server in a different cloud. For tests with less streams than the number of servers, the results shown are for one of the server receiving the stream via a streaming proxy. The CPU usage and median latencies are better than those of the other tests with 1 session and 1 stream for equal numbers of outgoing streams. However, message latencies are higher.

\subsubsection{2 Clouds, 3 Servers, 1 Collaborative Session, 2 Streams}

The results for this test are again better than the other results with 1 session and 2 streams, other than message latencies being higher.

\subsubsection{2 Clouds, 3 Servers, 1 Collaborative Session, 3 Streams}

The results for this test are worse compared to the other tests with 1 session and 3 streams including higher message latencies.

\subsubsection{2 Clouds, 3 Servers, 1 Collaborative Session, 4 Streams}

The results for this test are worse compared to the other tests with 1 session and 4 streams including higher message latencies.

\begin{table}
\caption{Median and Mean CPU, Latencies for 2 Cloud, 3 Server, 1 Session, 4 Stream}
\label{table:2cld_3serv_1sess_4str}
\begin{tabu} to\linewidth{|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|X[c]|}
\everyrow{\hline}
\hline
Number of Users & Median Latency (ms) & Mean Latency (ms) & Median Message Latency (ms) & Mean Message Latency (ms) & Median CPU (\%) & Mean CPU (\%) & Outgoing Streams\\
\taburowcolors 2{Gray!20..LimeGreen!50}
2 & 10.5 & 14.48 & 72 & 62.58 & 7.68 & 7.1 & 6 \\
3 & 12 & 17.82 & 73.5 & 99.92 & 20.29 & 16.41 & 10 \\
4 & 12.75 & 18.46 & 74 & 95.37 & 23.6 & 19.22 & 14 \\
5 & 13.2 & 22.16 & 73 & 166.32 & 27.58 & 22.13 & 18 \\
6 & 16.83 & 23.14 & 104 & 101.71 & 31.48 & 25.37 & 22 \\
7 & 19.14 & 40.63 & 154 & 373.56 & 32.32 & 26.8 & 26 \\
8 & 28.88 & 40.87 & 176 & 149.1 & 34.11 & 27.86 & 30 \\
9 & 51.33 & 81.45 & 165 & 142.56 & 29.08 & 24.97 & 34 \\
10 & 46.8 & 65.61 & 169 & 169.88 & 35.64 & 27.84 & 38 \\
\end{tabu}
\end{table}

\subsubsection{Test Conclusions and Identification}

The tests presented in the previous sections can be compared in a number of ways. The first way to compare them is to look at tests with a similar number of incoming streams and sessions. For example, looking at tests with 1 session and 1 client streaming, it can be noticed that the median latency and median CPU usage are close to each other for all tests for similar numbers of clients connected. Tests 1/1/1, 2/1/1, 2/2/1/1 and 2/3/1/1 all show similar results for 10, 20, 30 and 36 users. At the same time tests 1/2/1, 2/2/1 and 2/2/2/1 have similar results to each other, but have higher median latencies and similar CPU usage at 10, 20, 30 and 36 users compared to the tests with 1 session. This is most likely due to having more users connected. The same behaviour can be noticed for the tests with 2 clients streaming.

Another way to compare the tests results is by looking at results with the same number of collaboration sessions. By comparing these results it can be observed that as the number of incoming streams increases, latency decreases, while CPU is the same across the tests. For the same number of outgoing streams, tests 1/1/1, 1/1/2, 1/1/3 and 1/1/4 for example, show better results from 1 incoming streams to 4 incoming streams for 10 outgoing streams. This can be explained by the fact that to reach the same number of outgoing streams, as the incoming streams increase less users are in a session. The same behaviour can be observed across the other tests with equal number of sessions.

Looking at tests with the same number of sessions and streams but different numbers of servers, it can be noticed that the results are the same across different tests if the only variable is the number of servers. Similar behaviour can be observed if the only variable is the number of clouds, with everything else being constant. This confirms the assumption that better performance can be obtained by spreading the users across multiple servers.

If tests with similar numbers of outgoing streams are compared, it can be noticed that as the number of total users connected to each of the servers increases, the performance decreases. This however, does not apply just based on number of users connected. For example, comparing the results of tests with 30 outgoing streams, the worst result is shown by the 1/2/1 test which also has the most users connected (62 users), while the best result is shown by the test 1/1/2 which has 16 users connected. Tests for 1/1/1, 1/2/2 and 1/3/3, have similar numbers of users connected - 31 users, 32 users and 33 users respectively. However, 1/1/1 has much better results than 1/2/2 which has better results than 1/3/3. This could be explained by the fact that the tests with worse results have more incoming streams.

As such, it can be assumed that median latency is a function of number of users connected, and the number of incoming streams.

\subsubsection{Packet Sizes}

Using the data obtained from the tests an average value for packet sizes can be determined. Figure \ref{fig:1serv1streampacketsizes} shows the average packet sizes as reported by the Operating System for one of the tests. All other tests exhibit similar packet size distributions. Taking packet distribution boundaries (64, 128, 256, etc.) from Figure \ref{fig:1serv1streampacketsizes} as the sizes of packets, the average packet size can be determined to be equal to 482 bytes.

\begin{figure}
	\centering
		\includegraphics[width=0.65\columnwidth]{cloud_rrdPlugin_packet_size_1stream}
	\caption{Server Packet Sizes - Operating System}
	\label{fig:1serv1streampacketsizes}
\end{figure}

\subsection{Autonomic Computing Performance Tests}

This section will present the performance of the autonomic system presented in this thesis proposal. The system will be run on top of the test bed under various loads in order to determine how the system behaves when being overloaded or underloaded.