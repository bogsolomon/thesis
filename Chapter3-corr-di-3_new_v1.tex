\chapter{Models For Autonomic Computing Environments} % Write in your own chapter title
\label{Chapter3}
\lhead{Chapter \ref{Chapter3}. \emph{Models For Autonomic Computing Environments}} % Write in your own chapter title to set the page header
\section{Rationales}
Whether for work, play, or commerce, web-based applications have become the backbone of all enterprise activities and the norm for how people worldwide interact. Increasingly, users do not only expect fast application response, every time, but their definition of speed became a moving target. Thus, business statistics show that 500 milliseconds delay in load time can mean 11\% fewer page views, a 16\% decrease on customer satisfaction, and 7\% loss in conversions.
Web application delivery delays as small as 100 milliseconds measurably impact sales revenues, drop-off rates, and competitive advantage. Playing whack-a-mole with individual bottlenecks or niche solutions is simply inefficient, since a large variety of factors across the architecture and beyond can introduce bottlenecks and impact performance. There is therefore a need to implement solutions that encompass the entire application delivery chain.
In this landscape of the IT infrastructures coping with the above challenges, the autonomic computing solution is capable of intelligently and adaptively enabling the deployment of a variety of services and optimization technologies from a shared context to remove bottlenecks throughout the delivery chain, speed end-to-end application response, and deliver a comprehensive solution to the application delivery and optimization.
The autonomic computing approach spans environments, networks, client devices, and application infrastructures to deliver secure, all-the-time access and speed up the application response. It is predicted that the combination Autonomic Computing and Cloud Computing will be the wining solution in the application battle for higher performance in the future.
One of the most important steps in developing an autonomic computing system, whether the system is controlled via machine learning, control theory or any other method, is the development of an abstract model for the computing processes it automates.
Obtaining a mathematical model, is a compulsory step to take in any control problem at hand as once the model is developed various control methods can be devised and tests can then be applied to determine if the model is correct by comparing the model with the real systems. At the same time if the model is validated, then specific properties of the control system can be met such as  its stability, sensitivity, observability, controllability, etc. which show how responsive the control system is to various parameter, input, or disturbance variations. 

A model provides an abstract description of the controlled system and both the estimation of the system state, the prediction of the future state of the system and the decision of how to modify the system if needed, are based on that model. 

While a perfect model is impossible to develop for the system under investigation, it is important that the model represents with a certain accuracy  the state of the system and more importantly accurately modify itself to changes in the environment. If the modifications in the system do not translate into correct modifications of the model, even an initial correct model will be out of tune with the modeled system after a number of iterations. 

Because of the above, requirements for a good model have to encompass two contradictory criteria. First of all, such a model has to be simple enough to be usable in a control system. A control model cannot, and should not attempt to represent all the internal processes and structures of the real system. If all the complexity of the system is taken into consideration then designing such a model becomes an extremely complex task. Furthermore, if the model is too complex updating and using the model would become an expensive task to perform. On the other hand, a model has to be complex enough to capture the important details of the modeled system. If not enough information is captured in the model then the control system starts taking incorrect actions. For example, assume that the system under control exhibits a dual nature - under a certain perturbation value the output is linearly related to the input. After a certain perturbation value however, the output is exponentially related to the input. If the model captures the linear relation but not the exponential relation, even after the perturbation value is passed the control system would still take actions as if the relation was linear resulting in poor control performance.

An essential aspect of control theory is its flexible approach to modeling which means that even with an approximate model the final system, if well designed, will perform well, i.e. fulfills the performance criteria. Typically when designing a control system one considers finite-dimensional, linear, and deterministic models for the system to be controlled, even if the physical system is  nonlinear, with significant uncertainties. For example, considering robustness constraints the simplest model capturing the essential features of the system assure a functionality of the closed loop system within the specifications.

To conclude, it is impossible to describe a unique approach to develop a correct model, however in most cases model development will include examining how the internal variables of the system, the states, behave, as well as how any external inputs to the system affect the identified control parameters. Depending on the approach for modeling taken, at this step the structure of the model is defined, either via mathematical expressions for a control theoretic approach, neuron structure for a neural network approach or Bayesian rules for a Bayesian model. The model developed in this thesis proposal is a control theoretic model which will eventually use state space equations and stochastic differential equations to represent the dynamics of the model structure. 

\section{Stochastic and Flow-Based Models for Autonomic Computing Systems}

As mentioned in Chapter \ref{Chapter2}, processes taking place inside any Autonomic System have at their core queuing processes and as such the dynamics of the whole system will depend on the dynamic of the queuing process. 
In control terms, these processes take place in the controlled object called the Plant. Queuing processes have been used intensively in modeling computing and communication processes and are well described in the literature \cite{model:queue1}, \cite{model:queue2}, \cite{model:queue3}. There is also a rich literature related to the modeling of queueing processes through a fluid-flow and stochastic differential equations \cite{model:red1}, \cite{model:red2}, \cite{related:model:SeanMeyn2007}, \cite{model:fluidflow}, \cite{model:fluidflow2}, \cite{model:fluidflow3}, \cite{model:fluidflow4}. Typically, the fluid represents information stored in a buffer and waiting for being either processed or for transmission in the network.

This Chapter will introduce first a dynamic queuing process based on the flow-model. Eventually, the queuing process written as flow-model will be applied to Autonomic Computing modelling. The goal is to developed a model for the Autonomic Computing Environments in order to design an Autonomic Computing Controller which should control the Autonomic Computing Environment. The above controller supervises, for example, the resource allocation for executing the tasks stored in a buffer and forming a  queue to be resolved by the computer processor. The queue usually is resolved by yet another dynamic process which is either considered to be FIFO, General Processor, or Round-Robin algorithm, to name just a few.

In order to obtain a comprehensive model for the processes taking place in a computer which solves users requests representing  one or many invoked methods on one or many servers, the following high-level architecture  of the server is proposed.

\begin{figure}[htb!]
\includegraphics[width=0.95\linewidth]{DiagramComputingProcess}
\caption{A System Model of Computer Processes}
\label{fig:ControlModel_Queue_Scheduler}
\end{figure}

The mathematical model which will be developed in this Chapter will map the model of Figure \ref{fig:ControlModel_Queue_Scheduler} onto the corresponding mathematical expressions which describe each of the components of the above architecture. This leads to a model consisting of a series of three processes.

\begin{itemize}
\item A model for the invocation queue process due to the random generation of the user requests, considered as input to the queue
\item A model for the queue of virtualized servers assigned to the resolution of the users' requests, considering that any virtual server is dedicated to serve a fixed number of requests which correspond to its maximum capacity of CPU Load.
\item A model for the processor load and queue resolution, such as for example the First Come First Served policy.
\end{itemize}

In what follows, the mathematical background and the equations describing the arrival process, the queue, and the scheduler will be introduced guided by mathematical rigor. More mathematical formalisms related to random signals and processes will be given in Appendices.

In essence, the arrival of the requests for starting a computation process in a computer is random. So is the task which is triggered by the scheduler of the computer for solving the tasks and so is the execution of the task. 

Eventually the processor will have to put the tasks in a queue and the computer processor will be instructed to serve the queue. The queue in which the tasks are stored until they will enter in execution will have a variable length. This length will be therefore a process with random realizations, in fact a stochastic process if corresponding assumptions will be fulfilled. 

Thus there is a need to build a model for the queue length variation assuming that the processes taking place in regards to the queue are independent from a statistical point of view.

The approach taken in this Chapter relies on the probability theory method of introducing random variables as measurable mappings from a probability space to a general measurable space such that the expectation of the real-valued random variable can be obtained via an integral over the abstract set of points on which the random variable is defined.

Once a random variable is properly defined, a stochastic process can be defined as a continuously random walk indexed by the time variable.
Consequently the random walk will be defined by a discrete evolutionary process, while stochastic processes can be defined by a stochastic differential equation (SDE). 

 The mathematical concepts and a brief compendium of the theory of stochastic processes needed for understanding properly the queuing model, and thus the entire model of the task computation process will be given in the Appendix A. 

\subsection{Fluid Models for Queue and Queue Resolvers}

A fluid model or a stochastic fluid flow model is a mathematical model used to describe the fluid level in a reservoir subject to randomly determined periods of filling and emptying. Fluid flow models are widely used in the performance evaluation of computing processes, and in the transmission of packets in high-speed communication networks. The fluid model is an idealized deterministic model. In a communication network a unit of ``fluid'' corresponds to some quantities of packets. A fluid model is often a starting point to build a model for the impact of topology, processing rates, and external arrivals on network behavior.

In the case of networking processes the fluid represents the information stored in a buffer while waiting for transmission in a network. In a computer environment the fluid represents the tasks stirred in a buffer of tasks; the tasks wait to be entered into execution and terminated, though in this flow the tasks might be interrupted and brought back into execution. Those latter tasks are called to  be re-entrant. In a computer communication network, however, the flow is transmitted to the end of the path where the client awaits for the response. 

The arrival and service processes are modulated by a random external environment, and the quantity of interest is the behavior of the occupied size of the buffer. Various aspects of the fluid flow model were thoroughly investigated in the scientific literature such as \cite{flow:anick82}, \cite{flow:mitra88}, \cite{flow:stern91}, \cite{flow:Kulkarni98}, \cite{flow:sericola99}. The above references therein, considered the case where the random external environment is a Continuous-Time Markov Chain (CTMC) with a finite or infinite state space.

The literature about modeling communications of computer processing based on fluid flow models for queuing processes abounds in a variety of models which some are better than others. However, all the models have as the starting point the modeling of processes of level control.

A level control process in a tank is fueled by one or many flows flowing through a number of pipes, while the liquid/fluid is evacuated from the tank via another number of pipes through which the fluid flows with different speeds/quantities as in Figure \ref{fig:LevelControl}. This model is considered in what follows. The tank level control is modeled by the equation \ref{eq:LevelControlEq1}.

\begin{equation}
\begin{array}{l}
A \frac{dh}{dt} = q_{in}-q_{out} \\
q_{out}= a\sqrt{2gh}
 \label{eq:LevelControlEq1}
\end{array}
\end{equation}

where: $h \in \mathbb{R}$ is the level in the tank, $g \in \mathbb{R}$ is the acceleration of gravity, $A \in \mathbb{R}$ is the area of the tank, $q_{in} \in \mathbb{R}$ is the flow of fluid pumped into the tank, $q_{out} \in \mathbb{R}$ is the flow of fluid pumped out of the tank, and $a \in \mathbb{R}$ is the area of the of the hole in the tank through which the fluid is pumped out of the tank.

\begin{equation}
\begin{array}{l}
\frac{dh}{dt} + k_{1}\sqrt{h} = k_{2}q_{in} \\
q_{out}= k_{3}\sqrt{h}
\end{array}
 \label{eq:LevelControlEq2}
\end{equation}

where:

\begin{equation}
\begin{array}{l}
k_{1}= \frac{a \sqrt {2g}}{A} \\
k_{2} = \frac{1}{A} \\ 
k_{3} = \sqrt{2g}a
\end{array}
\end{equation}
 
where $k_{1}, k_{2}, k_{3} \in \mathbb{R}$ are constant parameters expressed in the physical units of MKS.

\begin{figure}[htb!]
\includegraphics[width=0.95\linewidth]{LevelControl}
\caption{Level/Fluid Flow Model}
\label{fig:LevelControl}
\end{figure}

\subsection{Stochastic Fluid Model for Queues of Processes}

For developing a fluid model for the autonomic computing environment the modeling of the retrieval of objects from Cache Clusters will be followed in order to model the virtual servers going up or down depending on the users' invocation patterns.  The model was developed in \cite{clevnot:fluidmodel} in order to capture  salient characteristics of processes taking place in content delivery in a distributed system. In regards to the invocations themselves, the model will consider these invocations waiting in a queue to be processed based on First Come First Served (FCFS) strategy of the General Processor model.

According to \cite{clevnot:fluidmodel}, in such a system the cache module provides the content which makes the object of the current query process, provided that the searched content is in the respective cache module; objects are stored in the cache memory in a queue and they are delivered as soon as the query for the object name takes place. 

The model is built assuming that requests for objects occur at a much faster time scale than the cache up/down events. Although all processes taking place in a computer are discrete, i.e. arrivals of query requests occur at discrete times, a fluid flow model will be used to describe the evolution of the queue of the query requests. In some respects the processes taking place in a computer system, distributed or not, are modeled by the same macroscopic stochastic fluid model. This was also the reason behind the above models introduced by the authors for modeling content distribution system.

Specifically, one assumes the followings:

\begin{itemize}
\item It is assumed that the processes taking place in an autonomic computing environment are random in nature, and that in time they are characterized by the formalisms used for the definition of any stochastic process. Therefore, a general framework for all stochastic processes are built as follows. 

It is considered that there exists a finite number of stochastic processes organized as a vector $\mu X$, which is  symbolized by $\mu X = [\mu X^1,...,\mu X^n]$, where each vector component is a stochastic process $\mu X^j = \{ \mu X^j_t \mid  t \in T\}$. Each random variable is defined over a probability space $(\Omega, \mathcal{F}, P) = (\mathbb{R}, \mathcal{B}(\mathbb{R}), P)$, where $\mathcal{B}(\mathbb{R})$ denotes a system of Borel sets over the set $\mathbb{R}$ .
It is assumed that $\mu X^j$ is stationary in wide sense \cite{shiryaev1995probability}. Therefore, $\forall t \in T$, $\mathbb{E}(X^j_t) = \mu$, and $\mathbb{E}(X^j_{t_1+s}, X^j_{t_1}) = \mathbb{E}(X^j_{t_2 + s}, X^j_{t_2})$.
Obviously when the vector has one single component the stochastic process is reduced to a scalar stochastic process.
%i.e. the average of the stochastic process is constant as well as the power of the stochastic process, while the %autocorelation function of the stochastic process $\mX, R(t,\tau)= R(\tau) where R(t, \tau) = E\left{ \m X * \m X %\right}$.
Under the above assumptions if $X$ is a random variable defined over the probability space  $(\Omega, \mathcal{F}, P)$ then the expected value of $X$, denoted by $E(X)$ or $\bf{E}(X)$ is the Lebesgue integral

\begin{equation}
E\left[X\right]= \int_{\Omega} XdP= \int_{\Omega} X(\omega)P(d\omega)
 \label{eq:Expectation}
\end{equation}
If there is a measurable function of $X$, $g(X)$, given that $X$ has a probability density function $f(X)$ then the expectation of the function $g$ is given by the inner product of $f$ and $g$:
\begin{equation}
E\left[g(X)\right]= \int_{-\infty}^{\infty} g(x)f(x)dx
 \label{eq:Expectation1}
\end{equation}

In particular, the above mathematical construction of stochastic processes will be applied to all processes which will be introduced for the description of the stochastic fluid flow model of queues of computing processes or tasks.
\item  Let $U\subseteq \mathcal{N} = \left\{1, 2, ...N\right\}$ where $\left\vert{\mathcal{N}}\right\vert=N$, be the number of servers currently processing users requests $\mathcal{R}= \left\{r_{1}, r_{2},...,r_{s}\right\}$, and assume that the servers are processing requests independently of each others, and that the time needed by a server to serve a user's request is exponentially distributed with a rate $\mu$, while the time a server is idle is also exponentially distributed with a rate $\lambda$.
\item User requests for tasks arrive at random times $\alpha_{1} < \alpha_{2} < ...$.
\item For the above random point process (e.g. a Poisson process) there exists an intensity $\sigma$
\item The tasks to be executed by the computing environment are requested by users according to the zeta probability distribution function.
\end{itemize}

The type of set chosen for $T$ creates two modeling schemes: if time is denumerable, hence isomorphic with $\mathbb{Z}$, then 
the total amount of traffic arriving at a queue $j$ in an interval of length $t$, $(-t, 0]$, is denoted by $A_j(t)$. In the discrete time setting this random variable is equal to: \[A_j(t) = \sum_{k=-t}^{0}X^j_k\] 

Another basic observation is that requests for executing a specific task, occur at a much faster time scale than the server processes a specific request. The above observation allows for replacing the arrivals of new tasks in the queue - which occur at discrete times in reality - with a fluid flow.

Specifically, let $x_{j}$ denote the number of tasks currently stored in the task buffer of a specific server $j\in U$.
The following assumptions are considered to hold.
\begin{itemize}
\item   When the server is running one assumes that $x_{j}$ grows at a continuous rate as a consequence of the continuous requests for content. This growth corresponds to a request directed to server $j$ and which is not immediately satisfied by it. 
\item The growth is slowed down by potential interruptions of the tasks in execution which eventually are brought back into execution. This can also be modeled as a re entrant fluid flow model for the reentrant task(s), in which the tasks are considered in the first place, as going out of the task buffer.
\item It is considered that there is a load balancing mechanism which distributes the requests uniformly to all servers in the cluster.
\end{itemize}

\subsection{The Fluid Flow Model for Autonomic Computing Processes}

The model for the autonomic computing processes will be similar to the \ref{eq:LevelControlEq1} from the mathematical point of view. Thus considering a host computer connected to the network that requires services via the network which are delivered by a single-server with a constant service rate as depicted in \ref{fig:QueueLengthControl}.

\begin{figure}[htb!]
\includegraphics[width=0.95\linewidth]{DiagramQueueModel}
\caption{Queue/Fluid Flow Model}
\label{fig:QueueLengthControl}
\end{figure}

A continuous time fluid flow model of the buffer dynamics is as follows

\begin{equation}
\begin{array}{l}
\frac{dx(t)}{dt} = u(t) -v(t) \\
\end{array}
 \label{eq:QueueControl}
\end{equation}

where $u(t)$ denotes the rate at which the users' requests are released to the network such that they are eventually queued by the servers and finally processed and represent the input to the system model described by Equation \ref{eq:QueueControl}, while the output of the system is $v(t)$, which represents the flow of processes which have been solved by the CPU.

A series of researches have been undertaken for the study of $u(t)$ in various technical incarnations. In \cite{model:queueKatabi} Katabi et all provide an empirical model for it considering a single link of capacity c (the total amount of traffic/fluid of the link). To begin the fluid flow model of the autonomic computing, the assumption is that there is no round trip delay as in the case of the model developed by Katabi et all.
Also, the Autonomic Computing paradigm was created to automate, among other management duties, the provisioning of virtual servers connected in server farms and assembled together in Data Centers. 

\begin{figure}[htb!]
\includegraphics[width=0.95\linewidth]{DiagramAutonomicComputingQueue}
\caption{Autonomic Computing of Server Farms deployed in Data Centers}
\label{fig:QueueAutonomicComputing}
\end{figure}

Thus the Autonomic computing environment shall only consider the infrastructure whose functionality shall assure the service of multiple clients served by virtual images of multiple servers. Multiple clients will therefore request the virtual servers to process multiple queues of processes by solving the above queues. As stated above, as a queue solution policy the FCFS strategy will be used.

Considering therefore, that there are $i \in \left\{N = \left\{ 0, 1, ...M \right\}\right\}$ users raising each a number of requests with rate $r_{i}(t)$ where each $r_{i}$ is a random variable defined over a probability space $(\Omega, \mathcal{F}, P) = (\mathbb{R}, \mathcal{B}(\mathbb{R}), P)$ as above.
At the same time one assumes that $r_{i}(t)$ is a continuous time real-valued stochastic process defined by the application $r_{i}:\mathbb{R}_{>0} \rightarrow \mathbb{N}_{>0}$ \cite{related:model:SeanMeyn2007} and  that there is a large number of computers which can host an unlimited numbers of virtual servers. 

Users' requests are considered as disturbances which push the computing process away from the controlled state of the system,  physically represented by CPU parameters such as the CPU load and the task execution time. It is also assumed that there is a load balancing policy which balances the load across all of the up nodes in the Autonomic Computing System.

Taking into account the above assumptions, the state of the system is denoted by $(i; x)$, where $i = \left\{0, 1,...,N\right\}$ is the number of up virtual servers and $x, 0 \le x \le c$ where $x$ is the total amount of fluid in the system which in this case comprises only the up servers, while $c$ denotes the total amount of fluid in the autonomic computing system, in other words the total capacity of processing users' requests by the total set of virtual servers.
The set of virtual servers under the control of the Autonomic Computing system is considered to contain $i$ servers which are processing the queue of processes activated by users' $r_{i}(t)$ requests for processing. There are also other $N-i$ virtual servers which are down due to the lack of users' requests.  Out of the total number of virtual servers which are up and running, $i\mu$ might finish the processing task and go down, while $(N-i)\lambda$ virtual servers which were initially down might go up, due to an increase of the users' requests for information.
Requests for servers arrive at random times $a_{1} < a_{2} ...$. One assumes that this random point process is a Poisson process with intensity $\sigma$ while responses to users' requests are processed at rate $\theta$.
The fluid arrival process is defined as follows: in $(Tn; Tn+1)$ the fluid arrival rate is $\sigma ( 1-\frac{x(t)}{c}) - r(x(t))$ if $N_{n}\in \left\{1, 2, ..N \right\}$ and is equal to $0$ if $N_{n} = 0$. In the above description of the fluid arrival process $r(x(t))$ is the processing rate function. Assuming that the buffer storing all users' request operates under a standard FIFO basis, the processing rate function is further defined by the ratio between the load $x(t)$ and the residence time $\theta(x)$.

The model for a virtual server plant will therefore describe the capability of the virtual server farm to serve new requests by provisioning virtual servers to respond to new processes. From this a number of servers are taken off the list of servers in use, when a number of new processes leave the system due to being served according to the FCFS scheduler.
   
Using the above notations, the fluid model for the virtual server system is described by the following stochastic differential equations:

\begin{equation}
\begin{array}{l}
dq(t)= (N-i)\frac{x(t)}{\frac{r_{i}(t)}{N}}dt +\tau(q(t))dW_{t} - f(q(t))dt \\
dx(t)= \sigma (1-\frac{x(t)}{c})dt- \theta(x(t))dt
\end{array}
\end{equation}  
    				
where N is the number of queues of invocations in the cloud based system, and $f(q(t))$ is referred to as the processing rate function and is defined as the ratio between the load of the buffer storing the invocations in a queue, and the processing or response time $h(q(t))$ of the process invoked by the user. It should be pointed out that there is no apriori assumption on the probability distribution of the incoming flow of invocations.

\begin{equation}
\begin{array}{l}
f(q(t))= \frac {q(t)}{h(q(t))}	\\
h(q(t))=  \frac {\alpha + q(t)}{\mu}
\end{array}
\end{equation}
								                            				
where  $W(t)$ is the `noise' (a Winner process), $\tau$ is the variance of $W(t)$, $\sigma$ is the Poisson process rate of the users' requests. If a linear form is selected for $h(q(t))$ then $\alpha$  and $\mu$ are positive numbers.
Both $\alpha$  and $\mu$ can be obtained assuming a constant invocation rate $\tau(q)dW_{t} = \lambda$ which will lead to a steady state length of the buffer $\overline{q}$ to the followings:
\begin{equation}
\begin{array}{l}
\lambda= \frac{\mu\overline{q}}{1+\overline{q}} \\
\overline{q} = \frac{\lambda}{\mu}
\end{array}
\label{eq:FluidFlowmodelforVServers}
\end{equation}

The previous model is a result of considering the length of queues of processes as stochastic processes described by Poisson Counters. The stochastic differential equation \ref{eq:FluidFlowmodelforVServers} is the second equation of this model and is a result of considering the invocation requests for processing translated in a number of virtual servers, capable to solve the invocations raised, considering that  the variations of the number of virtual servers up or down, and the FCFS strategy of solving the multiple queues of processes, and of virtual servers as Poisson processes with some rate be it $\sigma$, or $\theta$.

\subsubsection{Poisson Counter Driven Stochastic Differential Equations}
A Poisson counter process is described by a stochastic differential equation, whose solution generates a stochastic process. 

There are a few types of stochastic differential equations (SDE). Typically, SDEs incorporate random white noise which can be thought of as the derivative of Brownian motion (or the Wiener process). The presence of a stochastic process, namely a Poisson counter, will affect the valability of the application of Newton's rule of calculus, i.e. the equality:

\begin{equation}
\frac{d}{dt}g(x(t)) = g'(x) \frac {dx(t)}{dt}
\label{eq:NewtonRule}
\end{equation}

where $g(x)$ is continuous and differentiable, does not hold.
The purpose of this subsection is to generalize these types of equations in order to include noise.
Let $W_{t}$ be the Wiener process (aka Brownian motion).
A stochastic differential equation (SDE) is defined as in the relation given below.

\begin{equation}
\frac{d}{dt}x(t) = f(x)dt + \sigma(x)dW_{t}
\label{eq:SDE}
\end{equation}
which represent the change in $x$ given by deterministic changes $f$ with noise of variance $\sigma$

As it was mentioned above for stochastic processes the Newton rule does not apply. Instead there is It\^o's rule which is applied to for $g(x(t))$, a twice continuously differentiable, function.
\begin{equation}
dg(x(t)) = g'(x(t))dx  + {\frac{1}{2}}g''(x(t))\sigma^{2}(x(t))dt 
= \left\langle g'(x), f(x)dx  + g'(x)\sigma(x)\right\rangle dx + {\frac{1}{2}}g''(x)\sigma^{2}(x)dt
\label{eq:ItoRule}
\end{equation}

If the variable $x$ has the distribution $\rho(x,t)$ at the time $t$, then the evolution of the distribution 
function $\rho(x,t)$ is described by the following equation:
\begin{equation}
\frac{\partial \rho(x,t)}{\partial t} = -\frac{\partial\left[f(x) \rho(x,t)\right]}{\partial x} + 
{\frac{1}{2}}{\sigma^{2}(x)\rho(x,t)}dt 
\label{eq:Kolmogorov1}
\end{equation}
known also as the first Kolmogorov equation.
The connection between the Poisson counter and stochastic differential equations is realized by the dual representation of a stochastic integral and of stochastic differential equation by the following.

\begin{definition}
\textbf{Stochastic Integral}
\end{definition}
Consider a stochastic variable $x(t)$, which is the solution of the stochastic integral equation \ref{eq:StochasticIntegral} in the It\^o sens (\ref{eq:ItoRule})
\begin{equation}
 x(t) = x(0) + \int_{0}^{t} g(x(\tau))dN_{\tau}
\label{eq:StochasticIntegral}
\end{equation}
where $f(x(t))$ is a continuous function describing the deterministic changes in $x(t)$ generated by a noise of variance $g(x)$, and $N$ is a Poisson counter process with rate $\lambda$ defined by:

\begin{equation} 
\begin{array}{lcl} 
dN = \begin{cases} 1, & \mbox{at Poisson arrival} \\ 0, & \mbox{elsewhere} \end{cases}\\
\mathcal{E}[dN] = \lambda dt 
\end{array}
\label{eq:NPoisson}
\end{equation}
where $\lambda$ is the arrival rate of the Poisson process.

If on an interval where $N$ is constant, $x$ satisfies $\dot{x}(t) = f(x,t)$, and if when $N$ jumps at the moment $t=t_{1}$, $x$ changes according to 
\begin{equation}
\left[ \lim_{t \to + t_{1}^{+}} x(t) = g ( \lim_{t \to t_{1}^{-}} x(t,t_{1})) + \lim_{t \to t_{1}^{-}} x(t) \right]
\end{equation}
and $x(\cdot)$ is taken to be continuous from the left, then in the above conditions equation \ref{eq:StochasticIntegral} is written as:

\begin{equation}
dx(t) = f(x,t) dt + g(x)dN 
\label{eq:SumStochasticDifEq}
\end{equation}
which is called the Poisson Counter Driven Stochastic Differential Equation.

For many Poisson counters each defined by a counter $N_{i}$ and rate $\lambda_{i}$, the stochastic differential equation becomes
\begin{equation}
dx(t) = f(x,t) dt + \sum\limits_{i=1}^m g_{i}(x)dN_{i}
\label{eq:StochasticDifEq}
\end{equation}

Assume that $f$ and $g_{i}$  are sufficiently smooth (a smooth function has derivatives of all orders everywhere in its domain) and the initial density is small. Considering now an arbitrary and differentiable function $\psi(x (t))$, using the multivariate Ito's Rules, the following differential equation for $\psi(x(t))$ defined by $\psi: \mathbb{R}^{n} \rightarrow \mathbb{R}$  is obtained \cite{}:

\begin{equation}
d\psi(x) = \left\langle\frac{\partial\psi(x)}{\partial x}, f(x,t)\right\rangle dt + \sum\limits_{i=1}^m [\psi(x(t)+g_{i}(x(t))) - \psi(x(t))]dN_{i}
\end{equation}

In the expectation operator is applied on the expression above the following relationship holds:

\begin{equation}
\frac{dE(\psi(x))}{dt} = E\left[\left\langle \frac{\partial\psi(x)}{\partial x}, f(x,t)\right\rangle dt \right] + \sum\limits_{i=1}^m E\left[\psi(x+g_{i}(x),t) - \psi(x,t)\right]\lambda_{i}
\end{equation}

\subsubsection{Passage to Differential Equations}

If the following condition holds:

\begin{equation}
E[f(x)] \approx f(E[x])
\end{equation}

then the equation \ref{eq:StochasticDifEq} can be written as:

\begin{equation}
\begin{cases}
\frac{dq(t)}{dt}= (N-i)\frac{x(t)}{\frac{r_{i}(t)}{N}} +\tau(q) \frac{dW_{t}}{dt} - f(q(t)) \\
\frac{dx(t)}{dt} = \sigma (1-\frac{x(t)}{c})- \theta (x(t))
\end{cases}
\label{eq:FluidFlowmodelforProcessesQueue1}
\end{equation}

The above set of equations can be further linearized around the nominal value of $q(t)$ where the queue works in a permanent regime, be it $q_{s}$ in order to bring the set of equations to an ordinary differential equations:

The linearization using the Taylor series expansion,  will be applied to the  function $f(t)$ which bears the nonlinear component in 
\ref{eq:FluidFlowmodelforProcessesQueue1}.

\begin{equation}
f(t) = \frac{\mu_{q}{q_{s}}^2 + \mu_{q}q_{s}q_{0} - \mu_{q}{q_{0}}^2}{(q_{0}+q_{s})^{2}} + \frac{\mu_{q}q_{0}}{(q_{0}+q_{s})^{2}}q(t) 
\label{eq:FluidFlowmodelforServers6}
\end{equation}

Using the following notations:
\begin{equation}
\begin{array}{l}
a_{1} = \frac{\mu_{q} q_{0}}{(q_{0}+q_{s})^{2}} \\
b_{1} = \frac{\mu_{q}q_{s}}{(q_{0}+q_{s})^{2}}
\end{array}
\end{equation}
the equations can be written as:

\begin{equation}
\begin{cases}
\frac{dq(t)}{dt} + a_{1}q(t)= (N-i)\frac{x(t)}{r_{i}(t)} +\tau(q) \frac{dW_{t}}{dt} - b_{1} \\
\frac{dx(t)}{dt} = \sigma (1-\frac{x(t)}{c})-\theta x(t)
\end{cases}
\label{eq:FluidFlowmodelforServers7}
\end{equation}

as $f(t)$ can be written as:

\begin{equation}
f(t) = a_{1}x(t) + b_{1}
\label{eq:FluidFlowmodelforServers8}
\end{equation}

Using a block diagram representation the fluid flow model for computing processes can be represented as:

\begin{figure}[htb!]
\includegraphics[width=0.95\linewidth]{FluidFlowBlockDiagram}
\caption{Block diagram of the stochastic fluid flow model}
\label{fig:FluidFlowBlockDiagram}
\end{figure}
  
The above two SDE and ODE models for the cloud computing will be analyzed using MATLAB in Chapter \ref{Chapter5} and conclusions in regards to the usage of one or the other of the models will be made. The parameters of the model will be identified using a process similar to the one presented in \cite{bsolomon:identification}.
