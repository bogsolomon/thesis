% Chapter 1

\chapter{Introduction} % Write in your own chapter title
\label{Chapter1}
\lhead{Chapter \ref{Chapter1}. \emph{Introduction}} % Write in your own chapter title to set the page header

\section{Motivation and Research Objectives}

As IT departments have become more pervasive and more important for each and every company, as well as to our daily lives, they have also become more complex. In today's world people obtain their news and alerts online, shop online as well as communicate with friends and family via social networking sites. The complexity of the IT infrastructure has lead however to a situation where it is nearly impossible for humans to continue to manage and maintain the IT resources in a good state. Failures of the IT infrastructure in a company can have disastrous consequences for the company or even for the economy. In a world that is as fast as the current one an IT failure can result in lost sales, loss of customers to competitors or even payment of damages depending on how critical the infrastructure is.

Cloud computing exacerbates these issues by moving the IT infrastructure outside a company's premises. Where before each small enterprise would run its own small IT department, now large data centers provide IT services to multiple consumers and enterprises (SaaS, HaaS, IaaS). For the cloud providers the ability to maintain the systems' service level agreements and prevent service outages is paramount since long period of failures can open them to large liabilities from their customers. At the same time, cloud computing provides the ability for companies to pay only for the required resources and to scale up or down as more resources are needed or as resources are no longer required. Due to this capability, a solution is needed for cloud computing users in order to intelligently decide when to request more servers and when to release used servers. From the point of view of cloud computing providers, a solution is needed in order to move server loads such that only the required resources are used for a certain demand via virtualization. Server virtualization also increases the complexity of managing the servers in data centers, since suddenly one single hardware server can be running tens of virtual machines, each with its own load and processing requirements. Ensuring that the appropriate number of virtual machines are deployed on a hardware platform, such that the hardware is neither underutilized, nor that the virtual machines starve each other for resources is not a trivial administrative task. The issue becomes even more complex when the end user's location is taken into consideration. In order to achieve better response times and latency it is preferable to offer services as close as possible to the end user. Such approaches can be seen in Content Delivery Networks (CDN) \cite{akamai}, which cache web data in datacenters across the world in order to be closer to the end users. A similar approach is taken by Netflix in order to cache the most viewed shows and movies closer to the customers.

These are the problems that autonomic management systems attempt to solve. Autonomic computing systems are capable of self-managing by self-configuring, self-healing, self-optimizing and self-protecting, together known as self-CHOP. Such a system must be able to analyze itself at run time, determine its state, determine a desired state and then if necessary attempt to reach the desired state from the current state. Normally the desired state is a state that maintains the system's Service Level Agreement (SLA). For a self-configuring system for example, this could include finding missing libraries and installing them with no human intervention. A self-healing system would be able to determine errors in execution and recover to a known safe state. A self-optimizing system example would be a cluster of servers that dynamically adds and removes servers at run time in order to maintain a certain utilization and client response time. Finally, a self-protecting system example would be a server that detects a denial of service (DoS) attack and prevents it by refusing requests from certain Internet Protocol (IP) addresses.

The above goals of autonomic computing were mapped in the Manifesto \cite{IBM:AutonomicManifesto} on eight key requirements that a system must meet to be considered autonomic. An autonomic computing system must:

\begin{enumerate}
	\item ``Know itself'' by knowing its components, status, ultimate capacity, and other interconnected systems
	\item Configure and reconfigure itself under various and sometimes unpredictable situations. The configuration must be done automatically by the system
	\item Never settle for the status quo, and must always try to optimize the available resources, itself, and the way it works
	\item Be able to heal itself in case of malfunctions on some of its parts, and be able to recover its normal state of execution
	\item Be able to protect itself by identifying and responding to threats against various types of attacks, while maintaining system integrity and security
	\item Be aware of its environment and act according to the environmental needs
	\item Function in a heterogeneous and open way, and implement open standards
	\item Keep its complexity hidden from the end user
\end{enumerate}

Since the release of the Manifesto a number of research directions and a corresponding number of projects have been developed to look at how to create such intelligent systems which can substitute automatically generated operative commands to human intervention. Various approaches have been taken to reach the desired system self-adaptation. In terms of how the self-management behavior is reached two main architecture approaches have been used. In the first approach a global controller is added to the system, which gathers data from the various components, performs some form of analysis on the data, compares the analysis results with the desired goals and if the goals are breached by the predicted analysis, corrective actions are taken. Such approaches are seen in \cite{related:architecture:hierarch1}, \cite{related:model:lqm} and \cite{bogdan:seams07}. In the first type of approaches a cluster of servers for example, would have one controller which manages the entire cluster's adaptation. The second approach attempts to develop an autonomic system by developing small intelligent subsystems which achieve global self-adaptation through the interactions with other components. Such approaches can be seen in \cite{related:architecture:selflet} and \cite{related:architecture:unity}. In this second approach each server in a cluster would have its own intelligence which achieves local adaptation. The communication between components is then used in order to reach global system adaptation. Such systems can be developed by looking at Self-Organizing systems which are systems that are capable of reaching a desired state without the use of any central authority or plan. Such a system can be seen in Ashby's homeostat \cite{ashby:homeostat} which is capable of adapting itself to any perturbation in the system and reach back a stable state. Self-Organizing Networks have also been developed in recent years for mobile networks.

In this thesis, a \textbf{Self-Organizing autonomic system} which self-manages a cloud of servers is introduced. The system design and results of experiments obtained during system's tests are presented. The servers run a real-time collaborative application which allows the end users to share the same view, as well as to chat via text and video/audio streams. The cloud can be deployed in multiple locations and still allow any two users to communicate with each other while each user connects to the closest datacenter. The self-managing function ensures that all the servers in the same data-center maintain the same response time and CPU usage. At the same time, the self-organizing system can add or remove servers as needed when users connect or disconnect from the service.

The motivation to develop a geographically cloud based collaboration application is related to providing better performance parameters to users by locating the servers closer to the clients of the service. With the servers being placed closer to the clients, latency observed by clients can be lowered in most cases. The application is deployed on top of a public or private cloud such that it can be scaled by adding or removing virtual instances of the application. 

The motivation for developing an autonomic computing system to manage the cloud deployments is related to providing intelligent scaling of the cloud resources such that only the required resources are used at a given point in time. With the autonomic system managing the cloud resources, it can be ensured that servers are not idle when users do not need them. At the same time when demand increases the autonomic system ensures that more servers are started such that the latency and response time of the system are maintained to desired levels.

\section{Organization of the Thesis and Research Focus}

The thesis is organized such that it presents the self-organizing autonomic system moving from the design of the autonomic control system and of the geographically distributed application under control to various mechanisms which have to be set up to ensure the self-optimization of the cloud resources usage. Simulation results as well as results from the system run-time are also shown. The rest of the thesis  comprises the following.

Chapter \ref{Chapter2} presents the goals of the self-organizing system and also presents various related work in both autonomic architectures and self-organizing problems.

Chapter \ref{Chapter3} introduces the system under control, i.e. the real-time collaborative application, its cloud deployment and its functionality. This chapter also presents the requirements for self-optimization of the application.

Chapter \ref{Chapter4} describes the self-organization approach for the resource control of the media server cloud and for the collaborative application.

Chapter \ref{Chapter5} presents a test bed and performance tests run on the self-organizing self-optimizing system.

Finally chapter \ref{Chapter6} presents conclusions of the benefits provided by the proposed solution. Future developments of the architecture are also described.

The thesis's research focus will be on a number of contributions to the field of autonomic computing and distributed systems, as presented in \cite{bogdan:lindi}, \cite{bogdan:amgcc2013}, \cite{bogdan:cts2012}, \cite{bogdan:conti2010} and \cite{bogdan:miles2012chapter}. 

First of all, the research will focus on extending a single server real-time collaborative application into a geographically distributed cloud application. The geographic distributed system will provide better latency to its clients by allowing users to connect to servers closer to their location and which offer better Quality of Service ( QoS). The distributed nature of the system will be hidden from the users, such that from the point of view of users everyone is connected to a single server.

Second of all, the research will focus on a new self-organizing approach used for server scaling in data-centers and cloud systems which will allow heterogeneous resources to be part of the same server cloud, while normally a self scaling system will use homogeneous only resources. The designed self-organizing self-optimizing system will be split in two parts: a self-organizing system responsible for detecting breaches of the cloud's SLA and a second self-organizing algorithm which optimizes the number of servers used in the cloud when a breach is detected.

A test-bed is used in order to obtain results on the performance of the self-organizing autonomic system while managing the geographically distributed collaborative application.